{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir si los clientes se irán o se quedarán de Beta Bank\n",
    "Ayudaremos a Beta Bank a predecir si los clientes se irán o se quedarán basándonos en diferentes datos del cliente como su Puntuación de Crédito, Ubicación Geográfica, Sexo, Edad, cuánto tiempo lleva su deposito en el banco, Saldo, Número de Productos que utilizan, si tienen tarjeta de crédito, si son miembros activos y su Salario Estimado. Esta información se ha recogido en un conjunto de datos que vamos a analizar mediante modelos predictivos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents <a id='back'></a>\n",
    "\n",
    "* [Etapa 1. Descripción de los datos](#data_review)\n",
    "* [Etapa 2. Data preprocessing](#data_preprocessing)\n",
    "    * [2.1 Eliminación de algunas columnas](#column_elimination)\n",
    "    * [2.2 Valores ausentes](#missing_values)\n",
    "    * [2.3 Dummies para las columnas categóricas](#dummies)\n",
    "    * [2.4 Escala de las columnas numéricas](#scale_columns)\n",
    "    * [2.5 Características, objetivo y división de los datos](#features_target_segment)\n",
    "    * [2.7 Tener en consideración el desequilibrio de clases](#to_have_class_imbalance)\n",
    "* [Etapa 3. Examinar el equilibrio de clases](#class_balance)\n",
    "    * [3.1 Construcción de un modelo con el desequilibrio de clases](#class_imbalance)\n",
    "    * [3.2 Tener en consideración el desequilibrio de clases](#to_have_class_imbalance)\n",
    "    * [3.3 Ajuste del peso(weight) de la clase](#Class_weight_setting)\n",
    "    * [3.4 Sobremuestreo](#Upsampling)\n",
    "* [Etapa 4. Finalmente haremos pruebas en el conjunto de pruebas](#final_test)\n",
    "* [Conclusiones](#end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1. Descripción de los datos <a id='data_review'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información General"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar bibliotecas y módulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for dealing with dataframes\n",
    "from sklearn.tree import DecisionTreeClassifier #to deal with Decision Tree Models\n",
    "from sklearn.ensemble import RandomForestClassifier #to deal with Random Forest Models\n",
    "from sklearn.linear_model import LogisticRegression #to deal with Logistic Regression Models\n",
    "from sklearn.model_selection import train_test_split #to be able to split datasets\n",
    "from sklearn.preprocessing import StandardScaler #to be able to scale values\n",
    "from sklearn.utils import shuffle #to be able to shuffle columns\n",
    "from sklearn.metrics import f1_score, roc_auc_score #to be able to calculate model's f1_score\n",
    "#from sklearn.metrics import  #to be able to calculate model's auc-roc\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargaremos el archivo para leer nuestro dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('C:/Users/USER/Documents/proyectos/proyecto 8 (terminado)/Churn.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características\n",
    "-\n",
    "- `RowNumber`: índice de cadena de datos\n",
    "- `CustomerId`: identificador de cliente único\n",
    "- `Surname`: apellido\n",
    "- `CreditScore`: valor de crédito\n",
    "- `Geography`: país de residencia\n",
    "- `Gender`: sexo\n",
    "- `Age`: edad\n",
    "- `Tenure`: período durante el cual ha madurado el depósito a plazo fijo de un cliente (años)\n",
    "- `Balance`: saldo de la cuenta\n",
    "- `NumOfProducts`: número de productos bancarios utilizados por el cliente\n",
    "- `HasCrCard`: el cliente tiene una tarjeta de crédito (1 - sí; 0 - no)\n",
    "- `IsActiveMember`: actividad del cliente (1 - sí; 0 - no)\n",
    "- `EstimatedSalary`: salario estimado\n",
    "\n",
    "Objetivo\n",
    "-\n",
    "- `Exited`: El cliente se ha ido (1 - sí; 0 - no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nuestro objetivo(**\"target\"**) será la columna **\"Exited\"**, mientras que las demás columnas servirán como características(**\"features\"**). \n",
    "- En primer lugar, tenemos que tratar los valores que faltan ausentes en la columna **\"Tenure\"**. \n",
    "- En segundo lugar, tenemos que crear variables ficticias para las columnas categóricas.\n",
    "- A continuación, tendremos que normalizar (escalar) las columnas numéricas, excepto las que tienen valores binarios (1 ó 0) como **\"HasCrCard\"** e **\"IsActiveMember\"**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2. Procesamiento de datos <a id='data_preprocessing'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nombres de columnas en minúsculas\n",
    "Utilizaremos el método 'str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   rownumber        10000 non-null  int64  \n",
      " 1   customerid       10000 non-null  int64  \n",
      " 2   surname          10000 non-null  object \n",
      " 3   creditscore      10000 non-null  int64  \n",
      " 4   geography        10000 non-null  object \n",
      " 5   gender           10000 non-null  object \n",
      " 6   age              10000 non-null  int64  \n",
      " 7   tenure           9091 non-null   float64\n",
      " 8   balance          10000 non-null  float64\n",
      " 9   numofproducts    10000 non-null  int64  \n",
      " 10  hascrcard        10000 non-null  int64  \n",
      " 11  isactivemember   10000 non-null  int64  \n",
      " 12  estimatedsalary  10000 non-null  float64\n",
      " 13  exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#esto cambia los nombres de las columnas a minúsculas y guarda los cambios\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "#mostraremos de nuevo la info para ver los cambios efectuados\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de algunas columnas <a id='column_elimination'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminación de algunas columnas\n",
    "- Las columnas en cuestión son **\"rownumber\"**, **\"customerid\"**, y **\"surname\"**. RowNumber es básicamente el índice, sólo que empieza por 1 y no por 0. CusttomerId es sólo para diferenciar a los clientes con un numero único, Surname es también otro medio de identificación; ambos son diferentes para cada observación. Incluir estas columnas no ayudará con el entrenamiento de nuestros modelos. Así que tenemos que eliminar estas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   creditscore      10000 non-null  int64  \n",
      " 1   geography        10000 non-null  object \n",
      " 2   gender           10000 non-null  object \n",
      " 3   age              10000 non-null  int64  \n",
      " 4   tenure           9091 non-null   float64\n",
      " 5   balance          10000 non-null  float64\n",
      " 6   numofproducts    10000 non-null  int64  \n",
      " 7   hascrcard        10000 non-null  int64  \n",
      " 8   isactivemember   10000 non-null  int64  \n",
      " 9   estimatedsalary  10000 non-null  float64\n",
      " 10  exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df=data.drop(['rownumber', 'customerid', 'surname'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos eliminado las columnas éxitosamente y procederemos a tratar los valores asuentes de la columna Tenure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores ausentes <a id='missing_values'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratar Valores ausentes de la columna Tenure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore geography  gender  age  tenure    balance  numofproducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   hascrcard  isactivemember  estimatedsalary  exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., nan])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tenure\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creditscore          0\n",
      "geography            0\n",
      "gender               0\n",
      "age                  0\n",
      "tenure             909\n",
      "balance              0\n",
      "numofproducts        0\n",
      "hascrcard            0\n",
      "isactivemember       0\n",
      "estimatedsalary      0\n",
      "exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "variable = df.isna().sum()\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esto agrupa los 'datos' por la columna \"model_year\" y \"condition\", y calcula la mediana de las lecturas del odometer\n",
    "#y con el metodo .to_dict() que convierte el dataframe resultante en un diccionario con el nombre de la variable: median_mileage\n",
    "median_mileage = df.groupby([\"creditscore\"])['tenure'].median().to_dict()\n",
    "\n",
    "def odometer_missing_values(row):\n",
    "    if np.isnan(row['tenure']): \n",
    "        return median_mileage.get(row['creditscore'])\n",
    "    return row['tenure']\n",
    "    \n",
    "#aplica la función odometer_missing_values a la columna \"odometer\" de nuestro dataframe para efectuar los cambios\n",
    "df['tenure'] = df.apply(odometer_missing_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creditscore        0\n",
      "geography          0\n",
      "gender             0\n",
      "age                0\n",
      "tenure             2\n",
      "balance            0\n",
      "numofproducts      0\n",
      "hascrcard          0\n",
      "isactivemember     0\n",
      "estimatedsalary    0\n",
      "exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "variable = df.isna().sum()\n",
    "print(variable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos rellenar estas celdas vacías con el valor medio de la columna Tenure para no introducir ningún sesgo en nuestro conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,\n",
       "        6. ,  6.5,  7. ,  7.5,  8. ,  9. , 10. ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rellena las celdas que faltan con la mediana\n",
    "df['tenure']=df['tenure'].fillna(df['tenure'].median())\n",
    "df['tenure'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creditscore        0\n",
      "geography          0\n",
      "gender             0\n",
      "age                0\n",
      "tenure             0\n",
      "balance            0\n",
      "numofproducts      0\n",
      "hascrcard          0\n",
      "isactivemember     0\n",
      "estimatedsalary    0\n",
      "exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "variable = df.isna().sum()\n",
    "print(variable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "éxito todos los valores que faltaban en Tenure han sido sustituidos con la mediana"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummies para las columnas categóricas <a id='dummies'></a>\n",
    "Ahora tenemos 2 columnas categóricas: **\"Geography\"** y **\"Gender\"**. Vamos hacer un conteo de valores de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: geography, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para la columna Geography, tenemos 3 valores: Francia, Alemania y España. Cuando categorizamos esta columna, la columna será reemplazada por 3 columnas: Geography_in_France, Geography_in_Germany y Geography_in_ Spain. Cada columna tomará el valor 1 en la observación en la que la columna Geografía tenía el país como valor, de lo contrario obtiene 0. \n",
    "- Será lo mismo para la columna Género. Utilizaremos la función pd.get_dummies en toda la tabla 'df' ya que son las únicas columnas categóricas. Podemos eliminar una de las columnas ficticias para ambos escenarios porque un 0 en España y Alemania, por ejemplo, implica directamente un 1 para Francia. Para ello, configuremos el parámetro drop_first=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore  age  tenure    balance  numofproducts  hascrcard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sustituye las columnas categóricas por sus ficticias y elimina la primera columna ficticia de cada columna sustituida\n",
    "df=pd.get_dummies(df, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado con éxito los dummies para las columnas Geography y Gender"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escala de las columnas numéricas <a id='scale_columns'></a>\n",
    "Nuestras columnas numéricas son: **'creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary'**. Estas variables no tienen un rango definido, por lo que necesitamos escalarlas (o estandarizarlas) obteniendo sus puntuaciones z-scores. Hacemos esto porque el algoritmo normalmente pensaría que las variables con alta dispersión son más importantes y no queremos eso. Así que llamaremos a nuestra función StandardScaler(), tambien utilizaremos el metofo fit() para ajustar las columnas numéricas en ella y las transformarlas, entonces obtendremos nuestros valores escalados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.035627</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.381103</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.037224</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.381103</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.035627</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore       age    tenure   balance  numofproducts  hascrcard  \\\n",
       "0    -0.326221  0.293517 -1.035627 -1.225848      -0.911583          1   \n",
       "1    -0.440036  0.198164 -1.381103  0.117350      -0.911583          0   \n",
       "2    -1.536794  0.293517  1.037224  1.333053       2.527057          1   \n",
       "3     0.501521  0.007457 -1.381103 -1.225848       0.807737          0   \n",
       "4     2.063884  0.388871 -1.035627  0.785728      -0.911583          1   \n",
       "\n",
       "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
       "0               1         0.021886       1                  0   \n",
       "1               1         0.216534       0                  0   \n",
       "2               0         0.240687       1                  0   \n",
       "3               0        -0.108918       0                  0   \n",
       "4               1        -0.365276       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data[numeric])\n",
    "df[numeric] = scaler.transform(df[numeric])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos escalado correctamente los valores de las columnas numéricas de dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características, objetivo y división de los datos <a id='features_target_segment'></a>\n",
    "- objetivo será sin duda la columna **\"Exited\"**, mientras que el resto de columnas serán las características(**\"features\"**). Tenemos que dividir ambos conjuntos en conjuntos de entrenamiento, validación y prueba, que constituyen el 60%, el 20% y el 20% respectivamente.\n",
    "- Para ello, llamaremos a la función train_test_split() dos veces. La primera vez, dividiremos el conjunto de entrenamiento y un segundo conjunto estableciendo el parámetro test_size=0,4 (que es el porcentaje del conjunto de datos que debe constituir el segundo conjunto). La segunda vez, dividiremos el segundo conjunto anterior en tamaños iguales (test_size=0,5) y los resultados serán el conjunto de validación (20% del conjunto de datos original) y el conjunto de prueba (20% del conjunto de datos original). El random_state se igual  establecerá en 12345 y lo mantendremos igual durante todo el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df.drop('exited', axis=1)\n",
    "target=df['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.824585e-16</td>\n",
       "      <td>2.318146e-16</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-6.252776e-17</td>\n",
       "      <td>1.634248e-17</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>-2.877698e-17</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000050e+00</td>\n",
       "      <td>1.000050e+00</td>\n",
       "      <td>0.960214</td>\n",
       "      <td>1.000050e+00</td>\n",
       "      <td>1.000050e+00</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>1.000050e+00</td>\n",
       "      <td>0.433553</td>\n",
       "      <td>0.431698</td>\n",
       "      <td>0.497932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.109504e+00</td>\n",
       "      <td>-1.994969e+00</td>\n",
       "      <td>-1.726578</td>\n",
       "      <td>-1.225848e+00</td>\n",
       "      <td>-9.115835e-01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.740268e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.883586e-01</td>\n",
       "      <td>-6.600185e-01</td>\n",
       "      <td>-0.690152</td>\n",
       "      <td>-1.225848e+00</td>\n",
       "      <td>-9.115835e-01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.535935e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.522218e-02</td>\n",
       "      <td>-1.832505e-01</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.319639e-01</td>\n",
       "      <td>-9.115835e-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.802807e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.981094e-01</td>\n",
       "      <td>4.842246e-01</td>\n",
       "      <td>0.691748</td>\n",
       "      <td>8.199205e-01</td>\n",
       "      <td>8.077366e-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.572431e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.063884e+00</td>\n",
       "      <td>5.061197e+00</td>\n",
       "      <td>1.728174</td>\n",
       "      <td>2.795323e+00</td>\n",
       "      <td>4.246377e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.737200e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creditscore           age        tenure       balance  numofproducts  \\\n",
       "count  1.000000e+04  1.000000e+04  10000.000000  1.000000e+04   1.000000e+04   \n",
       "mean  -4.824585e-16  2.318146e-16     -0.000031 -6.252776e-17   1.634248e-17   \n",
       "std    1.000050e+00  1.000050e+00      0.960214  1.000050e+00   1.000050e+00   \n",
       "min   -3.109504e+00 -1.994969e+00     -1.726578 -1.225848e+00  -9.115835e-01   \n",
       "25%   -6.883586e-01 -6.600185e-01     -0.690152 -1.225848e+00  -9.115835e-01   \n",
       "50%    1.522218e-02 -1.832505e-01      0.000798  3.319639e-01  -9.115835e-01   \n",
       "75%    6.981094e-01  4.842246e-01      0.691748  8.199205e-01   8.077366e-01   \n",
       "max    2.063884e+00  5.061197e+00      1.728174  2.795323e+00   4.246377e+00   \n",
       "\n",
       "         hascrcard  isactivemember  estimatedsalary  geography_Germany  \\\n",
       "count  10000.00000    10000.000000     1.000000e+04       10000.000000   \n",
       "mean       0.70550        0.515100    -2.877698e-17           0.250900   \n",
       "std        0.45584        0.499797     1.000050e+00           0.433553   \n",
       "min        0.00000        0.000000    -1.740268e+00           0.000000   \n",
       "25%        0.00000        0.000000    -8.535935e-01           0.000000   \n",
       "50%        1.00000        1.000000     1.802807e-03           0.000000   \n",
       "75%        1.00000        1.000000     8.572431e-01           1.000000   \n",
       "max        1.00000        1.000000     1.737200e+00           1.000000   \n",
       "\n",
       "       geography_Spain   gender_Male  \n",
       "count     10000.000000  10000.000000  \n",
       "mean          0.247700      0.545700  \n",
       "std           0.431698      0.497932  \n",
       "min           0.000000      0.000000  \n",
       "25%           0.000000      0.000000  \n",
       "50%           0.000000      1.000000  \n",
       "75%           0.000000      1.000000  \n",
       "max           1.000000      1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean         0.203700\n",
       "std          0.402769\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 6000 2000 2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "#primera división para obtener conjuntos de entrenamiento tanto para las características como para el objetivo (60%) y un segundo conjunto (40%)\n",
    "features_train, features_test_valid, target_train, target_test_valid=train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "#2ª división del segundo conjunto anterior en los conjuntos de validación y prueba, división uniforme\n",
    "features_valid, features_test, target_valid, target_test=train_test_split(features_test_valid, target_test_valid, test_size=0.5, random_state=12345)\n",
    "#imprime las longitudes de los 3 conjuntos de características y objetivos que derivamos de la división\n",
    "print(len(features_train), len(target_train), len(features_valid), len(target_valid), len(features_test), len(target_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos correctamente nuestras características(**\"features\"**) y objetivos(**\"target\"**), y dividimos los datos en conjuntos de entrenamiento(**\"train\"**), validación(**\"valid\"**) y prueba(**\"test\"**) con sus proporciones correctas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3. Examinar el equilibrio de clases <a id='class_balance'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de un modelo con el desequilibrio de clases <a id='class_imbalance'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasificación del Árbol de Decisión**\n",
    "- Vamos a utilizar la función DecisiontreeClassifier(). llamaremos 2 hiperparámetros: **\"random_state\"** y **\"max_depth\"**. random_state tiene que ser el mismo en todos los ámbitos por lo que le daremos un valor fijo (12345). max_depth, sin embargo, es el hiperparámetro que vamos a iterar. Así que haremos un **\"bucle for\"**  para max_depth (en este caso del 1 al 10) y obtendremos sus puntuaciones F1 y valores AUC-ROC, que son métricas de la calidad del modelo.\n",
    "- El F1_score procesa el objetivo del conjunto de validación y las predicciones. La función roc_auc_score procesa el objetivo del conjunto de validación con las probabilidades de clase positivas de cada observación del conjunto válido. Para ello utilizamos la función predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1 F1 score = 0.0 AUC-ROC score = 0.6925565119556736\n",
      "Max depth 2 F1 score = 0.5217391304347825 AUC-ROC score = 0.7501814673449512\n",
      "Max depth 3 F1 score = 0.4234875444839857 AUC-ROC score = 0.7973440741838507\n",
      "Max depth 4 F1 score = 0.5528700906344411 AUC-ROC score = 0.813428129858032\n",
      "Max depth 5 F1 score = 0.5406249999999999 AUC-ROC score = 0.8221680508592478\n",
      "Max depth 6 F1 score = 0.5696969696969697 AUC-ROC score = 0.8164631712023421\n",
      "Max depth 7 F1 score = 0.5320813771517998 AUC-ROC score = 0.8090154489199669\n",
      "Max depth 8 F1 score = 0.5343511450381679 AUC-ROC score = 0.8084438267833703\n",
      "Max depth 9 F1 score = 0.5694249649368863 AUC-ROC score = 0.7822255760075976\n",
      "Max depth 10 F1 score = 0.53954802259887 AUC-ROC score = 0.7631231134957264\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    dt_model.fit(features_train, target_train)\n",
    "    dt_pred_valid=dt_model.predict(features_valid)\n",
    "    probabilities_valid = dt_model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    #imprimeremos la puntuación F1 comparando las predicciones con el objetivo del conjunto de validación y\n",
    "    # la puntuación auc_roc comparando el objetivo del conjunto de validación con las probabilidades de clase positivas.\n",
    "    print('Max depth', i, 'F1 score =', f1_score(target_valid, dt_pred_valid), 'AUC-ROC score =', \\\n",
    "         roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor **\"F1_score (~0,57)\"** se observa en **\"max_depth 6\"**, con un valor **\"AUC-ROC de ~0,82\"**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasificación Bosque Aleatorio**\n",
    "- Utilizaremos la función RandomForestClassifier(). Nuestro hiperparámetro random_state seguira siendo el mismo. Los hiperparámetros con los que iteraremos son max_depth y n_estimators. En este caso crearemos primero una lista vacía. A continuación, haremos un bucle for a través de los valores de profundidad máxima y, dentro de ese bucle, otro bucle a través de los valores de n_estimadores. Utilizaremos este bucle para crear modelos con diferentes permutaciones de los valores de max_depth y n_estimators que almacenaremos en la lista, de la que elegiremos el modelo con la puntuación f1 más alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, n_estimators=60, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "rf = []\n",
    "for i in range(1, 11):\n",
    "    for j in range(10, 101, 10):\n",
    "        rf_model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        rf.append(rf_model)\n",
    "    \n",
    "print(max(rf, key=lambda rf_model: f1_score(rf_model.predict(features_valid), target_valid)))\n",
    "#prints the model from the list with the highest f1 score based on predictions made using the \n",
    "#features of the validation set and the actual target of the validation set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo RandomForestClassifier con la puntuación F1 más alta tiene unos hiperparámetros **\"max_depth=10\"** y **\"n_estimators=10\"**. Así que vamos a entrenarlo específicamente con esos hiperparámetros y obtener un F1_score y un roc_auc_score. similar a la anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.58493353028065 AUC-ROC = 0.8386475541226357\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "best_rf_model.fit(features_train, target_train)\n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, best_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, probabilities_rf_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mejor puntuación F1 es ~0,59, con una puntuación AUC-ROC de ~0,85"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresión logística**\n",
    "- Utilizaremos la función LogisticRegression(). Nuestro random_state se mantendra el mismo. Los hiperparámetros max_depth y n_estimators no se aplican aquí. Todo lo que necesitamos es establecer un solucionador. Usaremos  **solver='liblinear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.33108108108108103 AUC-ROC = 0.7588677042566191\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "lr_model.fit(features_train, target_train)\n",
    "lr_valid_pred=lr_model.predict(features_valid)\n",
    "probabilities_lr_valid=lr_model.predict_proba(features_valid)\n",
    "probabilities_lr_one_valid=probabilities_lr_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, lr_valid_pred), 'AUC-ROC =', roc_auc_score(target_valid, probabilities_lr_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión Intermedia**\n",
    "- Observando los tres modelos podemos ver que el mejor de los 3 modelos fue el clasificador Random Forest con hiperparámetros **\"max_depth=10\"** y **\"n_estimators=10\"**, ya que obtuvo la puntuación F1 (aproximadamente 0,59) y la puntuación AUC-ROC (aproximadamente 0,84) más altas. Lo utilizaremos en el proximamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tener en consideración el desequilibrio de clases <a id='to_have_class_imbalance'></a>\n",
    "- Analizaremos el desequilibrio de clases para conocer las porciones de cada clase en el objetivo(target) del dataframe de entrenamiento. Para ello, utilizaremos la función value_counts() y estableceremos el parámetro **\"normalize=True\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.800667\n",
       "1    0.199333\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)\n",
    "#shows unique values of target_train and their shares (percentages) of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clase negativa (0) representa ~80% de los datos, mientras que la clase positiva (1) representa ~20 de los datos. Por tanto, hay 4 veces más en la clase negativa0 que en la clase positiva 1. \n",
    "- Veremos dos enfoques para analizar el desequilibrio de clases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balance clase del peso \"class_weight=balance\" <a id='Class_weight_setting'></a>\n",
    "- Para abordar este punto lo que tenemos que hacer aquí es establecer el hiperparámetro class_weight='balanced' al entrenar el modelo. Esto hará que la clase más rara (1 en este caso) tenga más peso. Aparte de eso, la sintaxis es la misma que antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6130177514792899 AUC-ROC = 0.8395480858219564\n"
     ]
    }
   ],
   "source": [
    "bal_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, class_weight='balanced')\n",
    "bal_rf_model.fit(features_train, target_train)\n",
    "bal_rf_pred = bal_rf_model.predict(features_valid)\n",
    "proba_bal_rf_valid=bal_rf_model.predict_proba(features_valid)\n",
    "proba_bal_rf_one_valid=proba_bal_rf_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, bal_rf_pred), 'AUC-ROC =', roc_auc_score(target_valid, proba_bal_rf_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuación F1 ya es mejor que antes, pero el valor AUC-ROC sufrió un ligero descenso casi imperceptible. La tasa de verdaderos positivos seguramente disminuyó un poco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.33108108108108103 AUC-ROC = 0.763895861939644\n"
     ]
    }
   ],
   "source": [
    "bal_lr_model = LogisticRegression(random_state=12345, solver='liblinear', class_weight = 'balanced')\n",
    "bal_lr_model.fit(features_train, target_train)\n",
    "bal_lr_valid_pred=bal_lr_model.predict(features_valid)\n",
    "probabilities_bal_lr_valid=bal_lr_model.predict_proba(features_valid)\n",
    "probabilities_bal_lr_one_valid=probabilities_bal_lr_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, lr_valid_pred), 'AUC-ROC =', roc_auc_score(target_valid, probabilities_bal_lr_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuacion F1 es casi similar antes del balance, pero el valor AUC-ROC aumento un poco a 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5533522190745988 AUC-ROC score = 0.7940753936329157\n"
     ]
    }
   ],
   "source": [
    "bal_dt_model = DecisionTreeClassifier(random_state=12345, max_depth=6, class_weight = 'balanced')\n",
    "bal_dt_model.fit(features_train, target_train)\n",
    "bal_dt_pred_valid=bal_dt_model.predict(features_valid)\n",
    "probabilities_bal_valid = bal_dt_model.predict_proba(features_valid)\n",
    "probabilities_bal_one_valid = probabilities_bal_valid[:, 1]\n",
    "#imprimeremos la puntuación F1 comparando las predicciones con el objetivo del conjunto de validación y\n",
    "# la puntuación auc_roc comparando el objetivo del conjunto de validación con las probabilidades de clase positivas.\n",
    "print('F1 score =', f1_score(target_valid, bal_dt_pred_valid), 'AUC-ROC score =', roc_auc_score(target_valid, probabilities_bal_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuacion \"F1_score (0,55)\" se observa en \"max_depth 6\", con un valor \"AUC-ROC de 0,79\". en esta ocasion podemos ver que el balance que me hemos hecho se observa un decremento tanto para F1 como para \"AUC-ROC\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobremuestreo(upsample) <a id='Upsampling'></a>\n",
    "En este punto, repetiremos la clase más rara y sus observaciones suficientes veces para que coincida por igual con la otra clase. Hemos visto antes que hay 4 veces más 0 clase negativa que 1 clase positiva, así que repetiremos los 1 y sus observaciones 4 veces para igualar los 0 en el conjunto de entrenamiento. Después de hacerlo, tendremos que barajarlos utilizando la función shuffle()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1] \n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9588, 11) (9588,)\n"
     ]
    }
   ],
   "source": [
    "#pasaremos como argumento el conjunto de características de entrenamiento y el objetivo de entrenamiento en la función upsample con una repetición de 4\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "print(features_upsampled.shape, target_upsampled.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos entrenar nuestro modelo utilizando estas características y objetivos sobremuestreados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6082251082251082 AUC-ROC = 0.8391201253334463\n"
     ]
    }
   ],
   "source": [
    "ups_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "ups_rf_model.fit(features_upsampled, target_upsampled)\n",
    "ups_rf_pred = ups_rf_model.predict(features_valid)\n",
    "proba_ups_rf_valid=ups_rf_model.predict_proba(features_valid)\n",
    "proba_ups_rf_one_valid=proba_ups_rf_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, ups_rf_pred), 'AUC-ROC =', roc_auc_score(target_valid, proba_ups_rf_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuación F1 es inferior a la obtenida al utilizar el ajuste por peso de clase. Sin embargo, ocurre lo contrario cuando se trata de AUC-ROC, mostrando de nuevo una ligera diferencia. La tasa de verdaderos positivos debe de haber aumentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.49056603773584906 AUC-ROC = 0.7638036160392937\n"
     ]
    }
   ],
   "source": [
    "ups_lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "ups_lr_model.fit(features_upsampled, target_upsampled)\n",
    "bal_lr_pred=ups_lr_model.predict(features_valid)\n",
    "proba_ups_lr_valid=ups_lr_model.predict_proba(features_valid)\n",
    "proba_ups_lr_one_valid=proba_ups_lr_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, bal_lr_pred), 'AUC-ROC =', roc_auc_score(target_valid, proba_ups_lr_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuación F1 es superior \"0.49\" a la obtenida al utilizar el ajuste por peso de clase. Cuando se trata de AUC-ROC \"0.76\" se mantuvo casi igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5533522190745988 AUC-ROC score = 0.7940753936329157\n"
     ]
    }
   ],
   "source": [
    "ups_dt_model = DecisionTreeClassifier(random_state=12345, max_depth=6)\n",
    "ups_dt_model.fit(features_upsampled, target_upsampled)\n",
    "ups_dt_pred_valid=ups_dt_model.predict(features_valid)\n",
    "proba_ups_valid = ups_dt_model.predict_proba(features_valid)\n",
    "proba_ups_one_valid = proba_ups_valid[:, 1]\n",
    "#imprimeremos la puntuación F1 comparando las predicciones con el objetivo del conjunto de validación y\n",
    "# la puntuación auc_roc comparando el objetivo del conjunto de validación con las probabilidades de clase positivas.\n",
    "print('F1 score =', f1_score(target_valid, ups_dt_pred_valid), 'AUC-ROC score =', roc_auc_score(target_valid, proba_ups_one_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuación F1 es igual \"0.55\" a la obtenida al utilizar el ajuste por peso de clase. Cuando se trata de AUC-ROC \"0.79\" se mantuvo igual."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión Intermedia**\n",
    "- Seguiremos adelante con el enfoque de ajuste del peso de la clase, ya que tiene la puntuación **\"F1 más alta de 0,61\"**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4. Finalmente haremos pruebas en el conjunto de pruebas <a id='final_test'></a>\n",
    "- Vamos a aplicar nuestro modelo (con el ajuste del peso de las clases) al conjunto de prueba. \n",
    "- Antes debemos entrenar el modelo utilizando los conjuntos de entrenamiento y validación; los uniremos utilizando la metodo **\"pd.concat()\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6014150943396226 AUC-ROC = 0.8434529457883793\n"
     ]
    }
   ],
   "source": [
    "#features_train_final=pd.concat([features_train] + [features_valid])\n",
    "#target_train_final=pd.concat([target_train] + [target_valid])\n",
    "final_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, class_weight='balanced')\n",
    "final_rf_model.fit(features_train, target_train)\n",
    "final_rf_pred = final_rf_model.predict(features_test)\n",
    "proba_rf_test=final_rf_model.predict_proba(features_test)\n",
    "proba_rf_one_test=proba_rf_test[:, 1]\n",
    "print('F1 score =', f1_score(target_test, final_rf_pred), 'AUC-ROC =', roc_auc_score(target_test, proba_rf_one_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuación final de F1 es de 0,60, por encima del umbral de 0,59."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión General <a id='end'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Procesamos el conjunto de datos escalando a las columnas numéricas, rellenando los valores que faltaban en la columna **\"Tenure\"** y obteniendo columnas ficticias a partir de las categóricas. Segmentamos los datos, sin tener en cuenta el desequilibrio de clases de 4:1, entrenamos los modelos de **árbol de decisión, bosque aleatorio y regresión logística**, y determinamos que el **\"modelo bosque aleatorio\"** era el mejor debido a su elevada **\"puntuación F1 (alrededor de 0,59)\"** y un **\"valor AUC-ROC de alrededor de 0,85\"**. \n",
    "- Teniendo en cuenta el desbalance de clases añadimos el hiperparametro class_weight=balance y utilizamos dos enfoques: Ajuste del peso de la clase decidimos por el primero ya que presentaba la puntuación F1 más alta (0,61), \n",
    "- Entrenamos el modelo con datos de entrenamiento y validación y lo aplicamos al conjunto de pruebas, obteniendo una puntuación final de **\"F1 de 0,60\"**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0a5ac10a1a851d14f37e2ba0888b0c57e559cf932b562d248dc3d9836eb42247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
